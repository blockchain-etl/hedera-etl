# Hedera ETL

[![Build Status](https://travis-ci.org/blockchain-etl/hedera-etl.png)](https://travis-ci.org/blockchain-etl/hedera-etl)
[![Discord](https://img.shields.io/badge/discord-join%20chat-blue.svg)](https://hedera.com/discord)

Hedera ETL populates BigQuery dataset with transactions and records generated by the Hedera Mainnet (or Testnet, if so configured).
- Extract: Stream of transactions (and records) are ingested from a GCP PubSub topic
- Transform: Filters for important fields, formats data types, etc
- Load: Streaming insert into BigQuery dataset

## Overview

![Ingestion](docs/images/hedera_etl_ingestion.png)

- PubSub topic contains JSON serialized hedera transactions published by
[Hedera Mirror Node](https://github.com/hashgraph/hedera-mirror-node). More details can be found [here](work-in-progress).

- Apache Beam pipeline pulls transactions from PubSub and inserts them into BigQuery. GCP Dataflow is used as runner for
the pipeline.

- Deduplication: The above ingestion pipeline gives at-least-once guarantee for persisting transaction into BigQuery.
Duplicates, if inserted, are removed using a cron job.

## Setup

### BigQuery

Schema for BigQuery table to store Hedera transactions is in
[schema.json](hedera-etl-dataflow/src/main/resources/schema.json) file. Please refer corresponding fields'
documentation in [hedera-protobuf](https://github.com/hashgraph/hedera-protobuf/tree/master/src/main/proto) for more
info about columns.

#### Creating tables

Use `bq` CLI to create the tables.

###### Transactions table

```bash
bq mk \
  --table \
  --description "Hedera network transactions" \
  --time_partitioning_field consensusTimestampTruncated \
  --time_partitioning_type DAY \
  --clustering_fields transactionType \
  project_id:dataset.transactions \
  hedera-etl-dataflow/src/main/resources/schema.json
```

###### Errors table

If an error is encountered when inserting a transaction into BigQuery, then the insert it retried. However, errors
for which retry would not help (for example, table row violating the schema), are not tried again and instead logged
into errors table.

```bash
bq mk \
  --table \
  --description "Hedera ETL Errors" \
  project_id:dataset.errors \
  hedera-etl-dataflow/src/main/resources/errors_schema.json
```

### Apache Beam Pipeline

###### Requirements

1. BigQuery tables for transactions and errors should exist
2. PubSub topic should exist
3. If using GCP Dataflow, a user or service account having following roles - BigQuery Data Editor, Dataflow Worker, and
   Pub/Sub Subscriber

###### Common parameters

Configure GCP project id, PubSub subscription/topic, and BigQuery tables.

```bash
PROJECT_ID=... # Set your project id
USE_SUBSCRIPTION=true  # Set to false to read from PubSub Topic
SUBSCRIPTION=projects/${PROJECT_ID}/subscriptions/subscriptionName # Can be left empty if USE_SUBSCRIPTION=false
TOPIC=  # Set PubSub Topic if USE_SUBSCRIPTION=true
TRANSACTIONS_TABLE=${PROJECT_ID}:dataset.transactions
ERRORS_TABLE=${PROJECT_ID}:dataset.errors
```

#### Running locally

```bash
cd hedera-etl-dataflow

mvn compile exec:java -PdirectRunner -Dexec.args=" \
  --inputSubscription=${SUBSCRIPTION}, \
  --inputTopic=${TOPIC}, \
  --outputTransactionsTable=${TRANSACTIONS_TABLE}, \
  --outputErrorsTable=${ERRORS_TABLE}"
```

#### Running on GCP Dataflow

1. Setup GCS bucket which is used for staging, templates, and temp location.

```bash
BUCKET_NAME=... # Set your bucket name
PIPELINE_FOLDER=gs://${BUCKET_NAME}/dataflow/pipelines/pubsub-to-bigquery
```

2. Build and upload template to GCS bucket

```bash
cd hedera-etl-dataflow

mvn compile exec:java \
 -Dexec.args=" \
 --project=${PROJECT_ID} \
 --stagingLocation=${PIPELINE_FOLDER}/staging \
 --tempLocation=${PIPELINE_FOLDER}/temp \
 --templateLocation=${PIPELINE_FOLDER}/template \
 --runner=DataflowRunner \
 --useSubscription=${USE_SUBSCRIPTION}"
```

3. Start Dataflow job using the template

```bash
gcloud dataflow jobs run pubsub-to-bigquery-`date +"%Y%m%d-%H%M%S%z"` \
 --gcs-location=${PIPELINE_FOLDER}/template \
 --parameters \
 "inputSubscription=${SUBSCRIPTION}, \
  inputTopic=${TOPIC}, \
  outputTransactionsTable=${TRANSACTIONS_TABLE}, \
  outputErrorsTable=${ERRORS_TABLE}"
```

### Deduplication

Work in progress.

## Code of Conduct
This project is governed by the [Contributor Covenant Code of Conduct](CODE_OF_CONDUCT.md). By participating, you are
expected to uphold this code of conduct. Please report unacceptable behavior to [oss@hedera.com](mailto:oss@hedera.com).

## License
[Apache License 2.0](LICENSE)
